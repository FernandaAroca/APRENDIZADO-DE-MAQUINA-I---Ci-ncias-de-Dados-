{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FernandaAroca/APRENDIZADO-DE-MAQUINA-I---Ci-ncias-de-Dados-/blob/main/C%C3%B3pia_de_C%C3%B3pia_de_ML7_ex_projeto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40b90843"
      },
      "source": [
        "<img src=\"http://meusite.mackenzie.br/rogerio/mackenzie_logo/UPM.2_horizontal_vermelho.jpg\"  width=300, align=\"right\">\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "# ***Título do seu projeto***\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYx9D4GZA5o9"
      },
      "source": [
        "#@title Identificação do Grupo\n",
        "\n",
        "#@markdown Integrantes do Grupo (*informe \\<TIA\\>,\\<nome\\>*)\n",
        "Aluno1 = \"'10730786, Fernanda G Aroca'\" #@param {type:\"string\"}\n",
        "Aluno2 = '1115677, Daniel Henrique' #@param {type:\"string\"}\n",
        "Aluno3 = 'None' #@param {type:\"string\"}\n",
        "Aluno4 = 'None' #@param {type:\"string\"}\n",
        "Aluno5 = 'None' #@param {type:\"string\"}\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Apresentação**"
      ],
      "metadata": {
        "id": "JlCIc2YooBW7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4-f8AtfKAn2"
      },
      "source": [
        "# Problema\n",
        "\n",
        "*Optamos por prever a inadimplência dos clientes classificação binária, um verdadeiro desafio para bancos e fintechs, que ajuda a minimizar prejuízos e aprimorar as decisões de crédito. A fim de atender a necessidade de dados originais, criamos programaticamente um conjunto de dados inicial com 2000 entradas, repletas de variáveis comuns idade, renda, pontuação, saldo, tempo de relacionamento, etc. e uma etiqueta de inadimplência simulada, oque posibilita o treinamento e a avaliação dos modelos.*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Referencial Teórico\n",
        "\n",
        "*O trabalho apoia-se nos princípios básicos do aprendizado supervisionado para classificação: definição da variável alvo, pré-processamento (escalonamento e codificação), engenharia de features, treino/validação e avaliação por métricas como precisão, recall, F1 e AUC. Para comparação de modelos seguimos a orientação prática de testar um modelo linear interpretável (regressão logística) e um ensemble mais flexível (Random Forest), avaliando trade-offs entre desempenho e interpretabilidade.\n",
        "Referências rápidas\n",
        "\n",
        "Material da disciplina — AULA 7: Seleção de modelos, classificação e preparação de dados. Texto de Apoio 7.\n",
        "Scikit-learn — Choosing the Right Estimator (guia prático).\n",
        "\n",
        "\n",
        "Scikit-learn — Classifier comparison (exemplos de comparação entre classificadores).\n",
        "\n",
        "\n",
        "Kaggle — Time Series (leitura recomendada sobre engenharia de features; complementar).\n",
        "\n",
        "\n",
        "Peixeiro, Time Series Forecasting in Python (referência sobre modelos estatísticos de séries temporais).\n",
        "\n",
        "*"
      ],
      "metadata": {
        "id": "7LtXrRFr4hg3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-pdJIiunIWL"
      },
      "source": [
        "# Metodologia\n",
        "\n",
        "*Geramos uma base original de 2000 registros, tratando o desafio como classificação binária, visando prever inadimplência. Variáveis comuns de crédito foram empregadas — idade, renda, score, tempo de relacionamento, número de produtos, saldo, salário estimado, indicador de atividade e posse de cartão — em conjunto com a variável alvo default. Os dados foram divididos de maneira estratificada em treino (70%) e teste (30%), onde no pré-processamento as variáveis numéricas foram escalonadas e o one-hot encoding aplicado nas categóricas tudo organizado num pipeline mantendo a reprodutibilidade. Treinamos dois modelos, um de regressão logística — interpretável, uma base, e outro Random Forest para relações não lineares comparando o desempenho por accuracy, precision, recall, F1 e ROC AUC, ademais examinamos a matriz de confusão e importâncias de variáveis, tentando entender os resultados.*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementação**"
      ],
      "metadata": {
        "id": "caAD2jBEn0KM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGFJyOm1Kdtd"
      },
      "source": [
        "# Base de Dados\n",
        "\n",
        "*A base de dados foi criada especificamente para o projeto, com 2.000 registros simulando informações de clientes, como idade, renda, score de crédito, saldo e atividade da conta. A variável alvo é default (inadimplência). Após a geração, os dados foram divididos em treino e teste (70/30) e passaram por pré-processamento: padronização das variáveis numéricas e one-hot encoding das categóricas, tudo organizado em um pipeline para garantir consistência.*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "RND = 42\n",
        "np.random.seed(RND)\n",
        "\n",
        "n = 2000\n",
        "\n",
        "age = np.random.randint(18, 76, size=n)\n",
        "annual_income = np.random.lognormal(mean=10.5, sigma=0.9, size=n)\n",
        "credit_score = np.clip((np.random.normal(loc=650, scale=70, size=n)).astype(int), 300, 850)\n",
        "tenure_years = np.random.randint(0, 11, size=n)\n",
        "num_products = np.random.choice([1,2,3,4], size=n, p=[0.5,0.3,0.15,0.05])\n",
        "balance = np.random.exponential(scale=20000, size=n)\n",
        "is_active = np.random.binomial(1, 0.7, size=n)\n",
        "has_cr_card = np.random.binomial(1, 0.8, size=n)\n",
        "estimated_salary = annual_income * np.random.uniform(0.85, 1.15, size=n)\n",
        "geography = np.random.choice(['Brazil', 'Portugal', 'Angola'], size=n, p=[0.85,0.1,0.05])\n",
        "\n",
        "score = (\n",
        "    -0.008 * credit_score +\n",
        "    0.00002 * balance -\n",
        "    -0.12 * tenure_years -\n",
        "    -0.6 * is_active -\n",
        "    -0.3 * has_cr_card -\n",
        "    -0.2 * num_products +\n",
        "    0.00001 * annual_income +\n",
        "    np.where(geography=='Brazil', 0.0, 0.15 * (geography=='Portugal'))\n",
        ")\n",
        "\n",
        "prob_default = 1 / (1 + np.exp(-score))\n",
        "prob_default = np.clip(prob_default, 0.01, 0.99)\n",
        "default = (np.random.rand(n) < prob_default).astype(int)\n",
        "\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'age': age,\n",
        "    'annual_income': annual_income,\n",
        "    'credit_score': credit_score,\n",
        "    'tenure_years': tenure_years,\n",
        "    'num_products': num_products,\n",
        "    'balance': balance,\n",
        "    'is_active': is_active,\n",
        "    'has_cr_card': has_cr_card,\n",
        "    'estimated_salary': estimated_salary,\n",
        "    'geography': geography,\n",
        "    'default': default\n",
        "})\n",
        "\n",
        "\n",
        "X = df.drop(columns=['default'])\n",
        "y = df['default']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, stratify=y, random_state=RND\n",
        ")\n",
        "\n",
        "\n",
        "numeric_features = [\n",
        "    'age','annual_income','credit_score',\n",
        "    'tenure_years','num_products','balance',\n",
        "    'estimated_salary'\n",
        "]\n",
        "\n",
        "categorical_features = ['is_active','has_cr_card','geography']\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "V_X2jqpl3UWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Modelo 1**\n",
        "\n",
        "*O primeiro modelo utilizado foi a Regressão Logística, escolhida por ser simples, interpretável e servir como baseline em problemas de classificação binária. Ele estima a probabilidade de inadimplência com base em uma combinação linear das variáveis.*\n"
      ],
      "metadata": {
        "id": "FGwyFHwtoO5m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Modelo 1:** Preparação dos Dados\n"
      ],
      "metadata": {
        "id": "hXaglI6JoaJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train_lr = X_train.copy()\n",
        "X_test_lr = X_test.copy()"
      ],
      "metadata": {
        "id": "-8gSVEHyoeLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Modelo 1:** Modelo\n"
      ],
      "metadata": {
        "id": "VyE3YKdQotLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "modelo1 = Pipeline(steps=[\n",
        "    (\"preprocessamento\", preprocessor),\n",
        "    (\"classificador\", LogisticRegression(max_iter=1000, random_state=42))\n",
        "])\n",
        "\n",
        "modelo1.fit(X_train_lr, y_train)\n",
        "y_pred_lr = modelo1.predict(X_test_lr)\n",
        "y_proba_lr = modelo1.predict_proba(X_test_lr)[:, 1]"
      ],
      "metadata": {
        "id": "a5YneTsaotLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Modelo 1:** Resultados\n"
      ],
      "metadata": {
        "id": "SRw3t2NnotVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Resultados – Modelo 1 (Regressão Logística)\")\n",
        "print(\"Acurácia:\", accuracy_score(y_test, y_pred_lr))\n",
        "print(\"Precisão:\", precision_score(y_test, y_pred_lr, zero_division=0))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred_lr, zero_division=0))\n",
        "print(\"F1:\", f1_score(y_test, y_pred_lr, zero_division=0))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba_lr))\n",
        "\n",
        "print(\"\\nMatriz de confusão:\")\n",
        "print(confusion_matrix(y_test, y_pred_lr))"
      ],
      "metadata": {
        "id": "kvwQvGDOotVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Modelo 2**\n",
        "\n",
        "*O segundo modelo empregado foi o Random Forest, um ensemble de múltiplas árvores de decisão capaz de captar relações não lineares e interações entre variáveis.*\n"
      ],
      "metadata": {
        "id": "n6sOVE9jo_jq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Modelo 2:** Preparação dos Dados\n"
      ],
      "metadata": {
        "id": "lBW3929po_jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_rf = X_train.copy()\n",
        "X_test_rf = X_test.copy()"
      ],
      "metadata": {
        "id": "VfJUfM16o_jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Modelo 2:** Modelo\n"
      ],
      "metadata": {
        "id": "z60H0esCo_jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "modelo2 = Pipeline(steps=[\n",
        "    (\"preprocessamento\", preprocessor),\n",
        "    (\"classificador\", RandomForestClassifier(n_estimators=200, random_state=42))\n",
        "])\n",
        "\n",
        "modelo2.fit(X_train_rf, y_train)\n",
        "y_pred_rf = modelo2.predict(X_test_rf)\n",
        "y_proba_rf = modelo2.predict_proba(X_test_rf)[:, 1]"
      ],
      "metadata": {
        "id": "GzbajY4fo_jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Modelo 2:** Resultados\n"
      ],
      "metadata": {
        "id": "f66UTm3So_js"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Resultados – Modelo 2 (Random Forest)\")\n",
        "print(\"Acurácia:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"Precisão:\", precision_score(y_test, y_pred_rf, zero_division=0))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred_rf, zero_division=0))\n",
        "print(\"F1:\", f1_score(y_test, y_pred_rf, zero_division=0))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba_rf))\n",
        "\n",
        "print(\"\\nMatriz de confusão:\")\n",
        "print(confusion_matrix(y_test, y_pred_rf))\n",
        "\n",
        "print(\"\\nImportância das variáveis (top 10):\")\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Recuperando nomes das features transformadas\n",
        "pre = modelo2.named_steps[\"preprocessamento\"]\n",
        "ohe = pre.named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
        "\n",
        "cat_names = []\n",
        "for col, cats in zip(categorical_features, ohe.categories_):\n",
        "    for c in cats:\n",
        "        cat_names.append(f\"{col}_{c}\")\n",
        "\n",
        "feature_names = numeric_features + cat_names\n",
        "\n",
        "importances = modelo2.named_steps[\"classificador\"].feature_importances_\n",
        "\n",
        "imp_df = pd.DataFrame({\n",
        "    \"feature\": feature_names,\n",
        "    \"importance\": importances\n",
        "}).sort_values(\"importance\", ascending=False)\n",
        "\n",
        "print(imp_df.head(10))"
      ],
      "metadata": {
        "id": "PJGbWBofo_jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kwoGZeSLRsX"
      },
      "source": [
        "# **Conclusão**\n",
        "\n",
        "*Ao longo do projeto, desenvolvi uma solução de aprendizado supervisionado para prever inadimplência a partir de uma base original criada especificamente para esse estudo. Após gerar os dados e aplicar o pré-processamento adequado, treinei dois modelos — Regressão Logística e Random Forest — buscando comparar suas performances. Apesar da alta acurácia obtida por ambos, os resultados mostraram que nenhum dos modelos conseguiu identificar os casos de inadimplência, principalmente devido ao forte desbalanceamento da base, em que a classe positiva representa menos de 3% dos registros. Isso reforça o que é apontado no referencial teórico: em problemas com classes desbalanceadas, acurácia não é uma métrica confiável, sendo mais adequado focar em recall, F1 e PR-AUC.\n",
        "\n",
        "Mesmo com essa limitação, o trabalho permitiu compreender bem o fluxo completo de criação de dados, preparação, modelagem e avaliação. Como continuação natural, melhorias futuras incluiriam técnicas de balanceamento (como SMOTE), ajuste de thresholds, validação cruzada e tuning de hiperparâmetros, além da possibilidade de gerar mais exemplos positivos para enriquecer o aprendizado dos modelos. Assim, o estudo demonstra com clareza como os modelos se comportam em cenários de risco de crédito e como ajustes adicionais são fundamentais para melhorar a detecção de inadimplentes.*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Referências**\n",
        "\n",
        "*Material da disciplina — AULA 7. Seleção de modelos, classificação e preparação de dados.\n",
        "\n",
        "Documentação do Scikit-learn – Guia de escolha de modelos.\n",
        "\n",
        "Documentação do Scikit-learn – Comparação de classificadores.*"
      ],
      "metadata": {
        "id": "hc0rg9YSzRz9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8crUBC3IQ3U_"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BluFtfHuCGzm",
        "cellView": "form"
      },
      "source": [
        "#@title Avaliação\n",
        "Completo = 10 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "#@markdown Projeto cumpre todos os itens pedidos.\n",
        "Relevancia = 9 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "#@markdown As seleções de dados e eventos para análise são relevantes e justificados.\n",
        "Tecnicas = 6 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "#@markdown As técnicas de empregadas são adequadas e corretamente aplicadas.\n",
        "Apresentacao = 7 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "#@markdown A apresentação dos resultados é clara e objetiva.\n",
        "Analise = 8 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "#@markdown As premissas de análise se justificam e a analise é correta.\n",
        "Conclusao = 7 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "#@markdown As conclusões são justificadas e relevantes\n",
        "Bonus = 0.5 #@param {type:\"slider\", min:0, max:1, step:0.5}\n",
        "#@markdown A critério do professor por inovações na abordagem e no uso de técnicas de Análise de Dados\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "2Gqw7hUZHyle",
        "outputId": "86e994a6-486f-43c2-9896-598a7878eaab"
      },
      "source": [
        "#@markdown ### Nota Final\n",
        "nota = Completo + Relevancia + Tecnicas + Apresentacao + Analise + Conclusao\n",
        "\n",
        "nota = nota / 6 + Bonus\n",
        "\n",
        "print(f'Nota final do trabalho {nota :.1f}')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "alunos = pd.DataFrame()\n",
        "\n",
        "lista_tia = []\n",
        "lista_nome = []\n",
        "\n",
        "for i in range(1,6):\n",
        "  exec(\"if Aluno\" + str(i) + \" !='None':  lista = Aluno\" + str(i) + \".split(','); lista_tia.append(lista[0]); lista_nome.append(lista[1].upper())\")\n",
        "\n",
        "alunos['tia'] = lista_tia\n",
        "alunos['nome'] = lista_nome\n",
        "alunos['nota'] = np.round(nota,1)\n",
        "print()\n",
        "alunos"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Completo' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3811864889.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#@markdown ### Nota Final\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnota\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCompleto\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mRelevancia\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mTecnicas\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mApresentacao\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mAnalise\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mConclusao\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnota\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnota\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m6\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mBonus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Completo' is not defined"
          ]
        }
      ]
    }
  ]
}